9 Oct 2016:
	didnt write the first 2 days' worth :(
	pretty easy to include, just point to the SDK's lib and includes, and 
	you're ready to use vulkan, no extension wranglers that i know of yet
	by the way, its following this https://vulkan-tutorial.com
	vk is meant to be a "car with a manual gearbox", you could screw it up 
	really badly, or make it more efficient
	to ease the use of this manual mode, you've got validation layers
	they're completely. you don't have to use them, but you'd look like 
	a prick if you didn't

10 Oct 2016:
	update your video card drivers you nutwit, validation layers wont work
	with your half-a-year-old drivers

11 Oct 2016:
	debug report callbacks with validation layers all set up and ready
	i dont understand them, neither do you
	almost everything done in vulkan is submitted into a command queue for
	sequential execution, better multithread work handling (hopefully)
	funcs to find a decent graphics card for vk to use

12 Oct 2016:
	logical device creation
	you can specify the command queue priority in your vk object, from 0 to 1
	just like OGL, its context needs a window handle to display to, we'll use
	GLFW, but SDL can be used, it's just not officially supported, but there's
	a library out there that eases its use with VK
	window surface needs to be created right after vkinstance creation, but
	there's a lot to cover regarding render targets etc.
	unlike opengl, you can do background rendering without using cheap hacks
	like making an invisible window
	the surface needs to find a good parent, aka queue family to adopt it
	nvidia cards allegedly support ~16 queue families, while
	AMD supports ~4+, and intel just 1
	use as many as possible, according to stack overflow answers
	https://www.reddit.com/r/vulkan/comments/46ckoc/queue_families/

13 Oct 2016:
	swap chains must be explicitly configured in VK, "thanks"
	then you choose the most appropriate pixel format to render as a surface
	presentation mode, gotta do that manually too, well it's kinda standard
	anyway, aka, whether you want doublebuffering/vsync
	
14 Oct 2016:
	fixed external link errors - vdeleter didnt work properly, likely the
	separately defined multi-template functions

15 Oct 2016:
	image views. in order to use any VkImage, like those in the swap chain,
	we have to make a VkImageView obj. literally a view onto the image
	it describes how to access the image and which part of the image to access
	eg. if it should just be treated like only its depth map existed
	a pure image view isnt totally suitable for setting as a render target
	yet though, we'd still need a framebuffer! doh

16 Oct 2016:
	shader pipelines - you specify what you need! dont need tesselation
	shaders? just omit it in the setup process, more tedius, but fine tuned
	unlike ogl, you have to precompile your shader code to bytecode :(
	(the SPIR-V format, used by VK and OCL)
	the VK SDK has a glsl-to-spir-v compiler, @ glslangValidator.exe
	in case you're an idiot and forgot about how shaders in glsl work,
	main() gets invoked per object (eg vertex, fragment), and you don't pass
	any parameters into main(), but are handled via global variables in your
	code. it's got built-in vector and matrix primitives
	if you're just pasting coordinates onto your screen, it would be
	on the framebuffer: 0px to 1920px (eg), and -1 to +1 on your clip coords,
	by the way, vulkan flipped the Y coords on clip space, so y=-1 is up top,
	and the Z value follows directX now, from 0 to 1 (dont need to manually
	inverse for better precision, like in opengl, yeah buddy)
	vertex buffers are tedious to set up on VK, so its gonna be postponed :(
	made a cute little bat file to compile them using the aforementioned
	compiler

17 Oct 2016:
	funcs just to link the compiled spir-v bytecode into our shader programs
	glsl code -> spir-v bytecode -> loaded into program -> turn it into a
	vk shader module -> link the modules together into a full pipeline
	fixed functions - unlike other gl's, in vulkan, you have to explicitly
	define all the functions and stuff, like the viewport size to the
	colour blending func, all in createGraphicsPipeline(); right now
	some of the fixed functions to configure are vert input, input assembly,
	viewports and scissors, the rasterizer, multisampling, depth and stencil
	testing, colour blending, and many more
	sad

18 Oct 2016:
	finished up specifying the fixed function config in pipeline creation
	read those comments in createGraphicsPipeline();
	too tired to recap here lol
	finished up createGraphicsPipeline();

19 Oct 2016:
	framebuffers - the attachments we specified during render pass creation
	are bound by wrapping them into a VkFrameBuffer object. each fb references
	all the VkImageView objects that represent the attachments. We need a fb
	for each image in the swapchain
	command pools, and after that -
	command buffers - you idiot hammond, you don't just call functions such as
	drawing/memory transfer operations in vulkan, you have to log and record
	all your wanted-actions into command buffer objects. this should be great
	as you could dispatch them multithreaded-ly (the whole reason i'm here)
	and you could just iterate through the command buffer in 1 main thread
	beautiful.

20 Oct 2016:
	drew the triangle lol, and again, I'm sorry future me, but I put the notes
	in the source itself, go look there instead. It's probably more helpful
	there too reference drawFrame();.

21 Oct 2016:
	Vertex buffers! stop putting your vertices in the god damn vert shader
	itself lol. we're gonna use the cpu-visible (your-program-visible) buffer
	using memcpy to copy the vert data to it directly. Afterwhich, a staging
	buffer will be used to copy the verts to high performance vram!
	head over to the Vertex struct in the constants.h file
	also check out the edited createGraphicsPipeline() func

22 Oct 2016:
	vert buffer creation!
	buffers in vulkan are regions of memory that's used for storing generic
	bullcrap that you need that can be read by the GPU. unlike vulkan objects
	we've been seeing so far, buffers don't automatically allocate memory for
	themselves :(((( we're in control now
	reference our createVertexBuffer();
	crepé! didn't do the swapchain recreation one :( TODO!

23 Oct 2016:
	recreateSwapChain() and onWindowResized() to call it, which is set up
	in initWindow()
	it's possible for vk to tell us that the swapchain isn't compatible
	anymore... during presentation :o, the vkAcquireNextImageKHR and
	vkQueuePresentKHR funcs can return values to signify this
	VK_ERROR_OUT_OF_DATE_KHR: the swap chain became incompatible with the
	surface and can't be used for rendering anymore :(
	VK_SUBOPTIMAL_KHR: simply unoptimal (can still be used), eg if the
	platform wants to fullscreen the window
	swapchain recreation/resizing sorted, but still a black screen :(
	ohhhhh, i turned the background clear colour to a lighter grey, and then
	i saw the triangle... it's just black. nice one me
	fixed: binding for vertex attribute 1 (the colour) specified a binding
	of 1 instead of 0

24 Oct 2016:
	Staging buffer! the vert buffer we've got ATM works... but isnt the
	"usual practice" lol. The memory type of that vert buff allows our CPU to
	access it. it may not be the optimal mem type for the gpu itself to read
	from. the best type has the VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT flag and
	is usually not accessible by the CPU on dedicated cards. today, we're gon
	make 2 vert buffers - one staging buffer in cpu accessible memory to
	upload upload the data from the vert array to... and the final vert buff
	in device memory (our gpu in this case). then we'll use a buffer copy cmd
	to move the data from the staging buff to the actual vert buff. 'aight

25 Oct 2016:
	Index buffer!
	chemistry revision :(

26 Oct 2016:
	finished up index buffer alloc'ing and binding
	if you want to be efficient, make 1 buffer for both vert data and indices

27 Oct 2016:
	Uniform buffers!
	so, we can pass around stuff like vertices and indices in good ol' buffers
	but what about global variables like specularity multipliers and stuff?
	we could put them as vert data, but then it'd be a waste of dupe memory,
	and it would require us to update the whole buffer each time theres a
	transformation change :/
	so we use Resource Descriptors! a descriptor is a way for shaders to
	freely access resources like buffs and images. We're gonna set up a buffer
	that contains the transformation matrices and have the vertex shader
	access them through a descriptor! neat'o
	Uage of these descriptors requires these 3 points:
	- specify a descriptor layout during pipeline creation
	- alloc a descriptor set from a descriptor pool
	- bind the descriptor set during rendering
	A descriptor layout tells ya the types of resources that are gonna be
	accessed by the pipline, just like how a render pass specifies the types
	of attachments thatll be accessed. A descriptor Set specifies the actual
	buffer or image resources that will be bound to these descriptors. just
	like how a framebuff specifies the image views to bind to render pass 
	attachments. The descriptor is then bound for the drawing commands just
	like vert and frame buffers!
	HEYO, we're gonna move onto three dimensional shiz now, and you know what
	that means? yea, an MVP matrix
	there's many types of descriptors, but we're gonna just use UBO's today

28 Oct 2016:
	busy :(

29 Oct 2016:
	happy birthday bob ross'o
	finished up ubo buffer creation and memcpy'ing, but havent done descriptor
	pools and sets yet

30 Oct 2016:
	woo! done with unform buffers, descriptor pools, sets and their layouts!
	head over to this->createDescriptorPool, Set, createGraphicsPipeline
	createCommandPool!